{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "#-*- coding:utf-8 -*-\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch.utils.data as data\n",
    "\n",
    "train = pd.read_csv(\"data.csv\",parse_dates=[\"Date\"])\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "wind1 = pd.read_csv(\"./dataset/wind1.csv\")\n",
    "wind2 = pd.read_csv(\"./dataset/wind2.csv\")\n",
    "wind3 = pd.read_csv(\"./dataset/wind3.csv\")\n",
    "wind4 = pd.read_csv(\"./dataset/wind4.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.optim.lr_scheduler import ExponentialLR\n",
    "\n",
    "# Hyper-Parameters\n",
    "sequence_length = 36\n",
    "input_size = 2\n",
    "hidden_size = 64\n",
    "num_layers = 3\n",
    "output_size = 4\n",
    "batch_size = 64\n",
    "num_epochs = 32\n",
    "learning_rate = 1e-5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "class mydata(data.Dataset):\n",
    "    def __init__(self, input_dat, y,seq_length):\n",
    "        self.input_dat = torch.tensor(input_dat).float()\n",
    "        self.y = torch.tensor(y).float()\n",
    "        self.seq_length = seq_length\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if idx >= self.seq_length - 1:\n",
    "            i_start = idx - self.seq_length + 1\n",
    "            x = self.input_dat[i_start:(idx-3),:]\n",
    "            y = self.y[(idx-3):(idx+1)]\n",
    "        elif idx>=3:\n",
    "            padding = self.input_dat[0].repeat(self.seq_length-idx-1,1)\n",
    "            x = self.input_dat[0:(idx-3),:]\n",
    "            x = torch.cat((padding,x),0)\n",
    "            y = self.y[(idx-3):(idx+1)]\n",
    "        else:\n",
    "            x = self.input_dat[0].repeat(self.seq_length-4,1)\n",
    "            padding_y = self.y[0].repeat(3-idx)\n",
    "            y = self.y[0:(idx+1)]\n",
    "            y = torch.cat((padding_y,y),0)\n",
    "        return x, y\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.input_dat.shape[0]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using two strategies,\n",
    "\n",
    "1. Test using MA data and Test relative error using MA data\n",
    "2. Test using original data and test re using original data\n",
    "\n",
    "Later, I'll figure out how to test using original data\n",
    "\n",
    "Split the 4th dataset to test set and the first 3 dataset as training set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training Sets\n",
    "train1 = np.array(wind1[[\"GridPowerMA\",\"WindSpdMA\"]][19:])\n",
    "train_data1 = mydata(train1, train1[:,1], sequence_length)\n",
    "train2 = np.array(wind2[[\"GridPowerMA\",\"WindSpdMA\"]][19:])\n",
    "train_data2 = mydata(train2, train2[:,1], sequence_length)\n",
    "train3 = np.array(wind3[[\"GridPowerMA\",\"WindSpdMA\"]][19:])\n",
    "train_data3 = mydata(train3, train3[:,1], sequence_length)\n",
    "\n",
    "# Test Sets\n",
    "test = np.array(wind4[[\"GridPowerMA\",\"WindSpdMA\"]][19:])\n",
    "test_target = np.array(wind4[\"GridPower\"][19:])\n",
    "test_data = mydata(test, test_target, sequence_length)\n",
    "test_data1 = mydata(test,test[:,1],sequence_length)\n",
    "\n",
    "# Data Loader\n",
    "train_dat1 = data.DataLoader(dataset=train_data1, batch_size=batch_size, shuffle=True)\n",
    "train_dat2 = data.DataLoader(dataset=train_data2, batch_size=batch_size, shuffle=True)\n",
    "train_dat3 = data.DataLoader(dataset=train_data3, batch_size=batch_size, shuffle=True)\n",
    "test_dat = data.DataLoader(dataset=test_data, batch_size=batch_size, shuffle=True)\n",
    "test_dat1 = data.DataLoader(dataset=test_data1, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Build RNN(LSTM)\n",
    "class RNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_layers, output_size):\n",
    "        super(RNN, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        self.lstm = nn.LSTM(input_size, hidden_size, num_layers, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_size,output_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # set initial hidden and cell states\n",
    "        h0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(device) \n",
    "        c0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(device)\n",
    "        \n",
    "        # Forward propagate LSTM\n",
    "        out, _ = self.lstm(x, (h0, c0))  # out: tensor of shape (batch_size, seq_length, hidden_size)\n",
    "\n",
    "        # Decode the hidden state of the last time step\n",
    "        out = self.fc(out[:, -1, :])\n",
    "        return out\n",
    "\n",
    "lstm_ma = RNN(input_size, hidden_size, num_layers, output_size).to(device)\n",
    "lstm_o = RNN(input_size,hidden_size, num_layers, output_size).to(device)\n",
    "\n",
    "# Loss and optimizer\n",
    "criterion = nn.MSELoss()\n",
    "op_ma = torch.optim.Adam(lstm_ma.parameters(), lr=learning_rate)\n",
    "op_o = torch.optim.Adam(lstm_ma.parameters(), lr=learning_rate)\n",
    "scheduler_ma = ExponentialLR(op_ma,gamma=0.9)\n",
    "scheduler_o = ExponentialLR(op_o,gamma=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.11506940424442291\n",
      "0.08616837114095688\n",
      "0.04883268475532532\n",
      "0.11819012463092804\n",
      "0.07497565448284149\n",
      "0.04663965851068497\n",
      "0.12317994982004166\n",
      "0.08749169111251831\n",
      "0.045602474361658096\n",
      "0.11659349501132965\n",
      "0.07471343874931335\n",
      "0.04418050870299339\n",
      "0.1252126544713974\n",
      "0.08391319960355759\n",
      "0.04215799644589424\n",
      "0.1365242749452591\n",
      "0.08576434850692749\n",
      "0.04119434580206871\n",
      "0.11839771270751953\n",
      "0.07265973836183548\n",
      "0.04051946848630905\n",
      "0.12625408172607422\n",
      "0.06651438772678375\n",
      "0.038536012172698975\n",
      "0.11431173980236053\n",
      "0.07074868679046631\n",
      "0.03774336725473404\n",
      "0.14962518215179443\n",
      "0.0666569396853447\n",
      "0.03605664148926735\n",
      "0.14610067009925842\n",
      "0.08357097208499908\n",
      "0.03567812219262123\n",
      "0.12921138107776642\n",
      "0.06921297311782837\n",
      "0.03445029631257057\n",
      "0.09498874843120575\n",
      "0.0701906681060791\n",
      "0.03517436236143112\n",
      "0.1192149743437767\n",
      "0.06775183230638504\n",
      "0.03388034552335739\n",
      "0.09327922761440277\n",
      "0.06597660481929779\n",
      "0.033656228333711624\n",
      "0.11588398367166519\n",
      "0.06847784668207169\n",
      "0.03366796672344208\n",
      "0.11009712517261505\n",
      "0.0631783977150917\n",
      "0.03182493895292282\n",
      "0.12845221161842346\n",
      "0.06378594785928726\n",
      "0.031532563269138336\n",
      "0.13587065041065216\n",
      "0.06426644325256348\n",
      "0.031003765761852264\n",
      "0.09977389872074127\n",
      "0.0664248913526535\n",
      "0.0312797985970974\n",
      "0.08447348326444626\n",
      "0.05726182460784912\n",
      "0.03127064183354378\n",
      "0.09790246188640594\n",
      "0.05534488707780838\n",
      "0.03098904713988304\n",
      "0.07583922147750854\n",
      "0.059758465737104416\n",
      "0.02984912320971489\n",
      "0.10643089562654495\n",
      "0.06399282813072205\n",
      "0.030385328456759453\n",
      "0.12471368908882141\n",
      "0.061409540474414825\n",
      "0.03066663071513176\n",
      "0.1081642135977745\n",
      "0.07012628018856049\n",
      "0.029829390347003937\n",
      "0.12093528360128403\n",
      "0.060816727578639984\n",
      "0.030253687873482704\n",
      "0.10956498235464096\n",
      "0.05991757661104202\n",
      "0.030131308361887932\n",
      "0.09461469948291779\n",
      "0.059443943202495575\n",
      "0.02952512353658676\n",
      "0.07649686932563782\n",
      "0.06039152666926384\n",
      "0.029030410572886467\n",
      "0.10064104944467545\n",
      "0.05033227428793907\n",
      "0.03014487400650978\n",
      "0.09061848372220993\n",
      "0.06280089914798737\n",
      "0.02953270636498928\n"
     ]
    }
   ],
   "source": [
    "# Training\n",
    "for epoch in range(num_epochs):\n",
    "    for i, (value,labels) in enumerate(train_dat1):\n",
    "        value = value.reshape(-1,sequence_length-4,input_size).to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        # forward pass\n",
    "        outputs = lstm_ma(value)\n",
    "        loss = criterion(outputs.squeeze(),labels.squeeze())\n",
    "\n",
    "        # optimization step\n",
    "        op_ma.zero_grad()\n",
    "        loss.backward()\n",
    "        op_ma.step()\n",
    "\n",
    "        if i % 500 == 0:\n",
    "            print(loss.item())\n",
    "    \n",
    "    for i, (value,labels) in enumerate(train_dat2):\n",
    "        value = value.reshape(-1,sequence_length-4,input_size).to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        # forward pass\n",
    "        outputs = lstm_ma(value)\n",
    "        loss = criterion(outputs.squeeze(),labels.squeeze())\n",
    "\n",
    "        # optimization step\n",
    "        op_ma.zero_grad()\n",
    "        loss.backward()\n",
    "        op_ma.step()\n",
    "\n",
    "        if i % 500 == 0:\n",
    "            print(loss.item())\n",
    "    \n",
    "    for i, (value,labels) in enumerate(train_dat3):\n",
    "        value = value.reshape(-1,sequence_length-4,input_size).to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        # forward pass\n",
    "        outputs = lstm_ma(value)\n",
    "        loss = criterion(outputs.squeeze(),labels.squeeze())\n",
    "\n",
    "        # optimization step\n",
    "        op_ma.zero_grad()\n",
    "        loss.backward()\n",
    "        op_ma.step()\n",
    "\n",
    "        if i % 500 == 0:\n",
    "            print(loss.item())\n",
    "    \n",
    "    scheduler_ma.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.1123)\n",
      "0.23499589288329475\n",
      "0.979828417301178\n",
      "0.14867109805345535\n",
      "0.5052631578947369\n"
     ]
    }
   ],
   "source": [
    "# Evaluation\n",
    "lstm_ma.eval()\n",
    "mse = 0\n",
    "i = 0\n",
    "re = np.array([])\n",
    "with torch.no_grad():\n",
    "    for values, labels in test_dat:\n",
    "        values = values.reshape(-1,sequence_length-4,input_size).to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        outputs = lstm_ma(values)\n",
    "        mse += torch.sum((outputs-labels)**2)\n",
    "        i += len(labels.flatten())\n",
    "        re_tmp = np.array(np.abs(labels.flatten()-outputs.flatten()))\n",
    "        re = np.concatenate((re,re_tmp),axis=0)\n",
    "print(mse/i)\n",
    "mean_rerror = np.mean(re)\n",
    "max_rerror = np.max(re)\n",
    "median_rerror = np.median(re)\n",
    "print(mean_rerror)\n",
    "print(max_rerror)\n",
    "print(median_rerror)\n",
    "idx = re <= 0.15\n",
    "idx = idx + 0\n",
    "print(sum(idx)/len(idx))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0640)\n",
      "0.22141658261156918\n",
      "0.567604660987854\n",
      "0.20742802321910858\n",
      "0.30701754385964913\n"
     ]
    }
   ],
   "source": [
    "# Evaluation using ma data\n",
    "lstm_ma.eval()\n",
    "mse = 0\n",
    "i = 0\n",
    "re = np.array([])\n",
    "with torch.no_grad():\n",
    "    for values, labels in test_dat1:\n",
    "        values = values.reshape(-1,sequence_length-4,input_size).to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        outputs = lstm_ma(values)\n",
    "        mse += torch.sum((outputs-labels)**2)\n",
    "        i += len(labels.flatten())\n",
    "        re_tmp = np.array(np.abs(labels.flatten()-outputs.flatten()))\n",
    "        re = np.concatenate((re,re_tmp),axis=0)\n",
    "print(mse/i)\n",
    "mean_rerror = np.mean(re)\n",
    "max_rerror = np.max(re)\n",
    "median_rerror = np.median(re)\n",
    "print(mean_rerror)\n",
    "print(max_rerror)\n",
    "print(median_rerror)\n",
    "idx = re <= 0.15\n",
    "idx = idx + 0\n",
    "print(sum(idx)/len(idx))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If just input the original data, let's see what will happen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training Sets\n",
    "train1 = np.array(wind1[[\"GridPower\",\"WindSpd\"]][19:])\n",
    "train_data1 = mydata(train1, train1[:,1], sequence_length)\n",
    "train2 = np.array(wind2[[\"GridPower\",\"WindSpdMA\"]][19:])\n",
    "train_data2 = mydata(train2, train2[:,1], sequence_length)\n",
    "train3 = np.array(wind3[[\"GridPower\",\"WindSpd\"]][19:])\n",
    "train_data3 = mydata(train3, train3[:,1], sequence_length)\n",
    "\n",
    "# Data Loader\n",
    "train_dat1 = data.DataLoader(dataset=train_data1, batch_size=batch_size, shuffle=True)\n",
    "train_dat2 = data.DataLoader(dataset=train_data2, batch_size=batch_size, shuffle=True)\n",
    "train_dat3 = data.DataLoader(dataset=train_data3, batch_size=batch_size, shuffle=True)\n",
    "test_dat = data.DataLoader(dataset=test_data, batch_size=batch_size, shuffle=True)\n",
    "test_dat1 = data.DataLoader(dataset=test_data1, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.12683239579200745\n",
      "0.09166690707206726\n",
      "0.030759423971176147\n",
      "0.1118517816066742\n",
      "0.07797396183013916\n",
      "0.031212294474244118\n",
      "0.15039777755737305\n",
      "0.08383212983608246\n",
      "0.029711220413446426\n",
      "0.13405296206474304\n",
      "0.08904244005680084\n",
      "0.02995527721941471\n",
      "0.15551041066646576\n",
      "0.08792262524366379\n",
      "0.029293227940797806\n",
      "0.1256210058927536\n",
      "0.09017501026391983\n",
      "0.028934204950928688\n",
      "0.12162861973047256\n",
      "0.08672021329402924\n",
      "0.029002349823713303\n",
      "0.13259896636009216\n",
      "0.08043123036623001\n",
      "0.02854018844664097\n",
      "0.1169380396604538\n",
      "0.08782452344894409\n",
      "0.027633359655737877\n",
      "0.14876282215118408\n",
      "0.0848732590675354\n",
      "0.02748604118824005\n",
      "0.10541661828756332\n",
      "0.08768942952156067\n",
      "0.028077062219381332\n",
      "0.12498548626899719\n",
      "0.0815960243344307\n",
      "0.02758021280169487\n",
      "0.13250288367271423\n",
      "0.09021377563476562\n",
      "0.027633799239993095\n",
      "0.13884590566158295\n",
      "0.0887162908911705\n",
      "0.02710086852312088\n",
      "0.1288071721792221\n",
      "0.0899745300412178\n",
      "0.02767215296626091\n",
      "0.14316865801811218\n",
      "0.09367043524980545\n",
      "0.02682441659271717\n",
      "0.11877445876598358\n",
      "0.08989989757537842\n",
      "0.02629123255610466\n",
      "0.13059750199317932\n",
      "0.08414017409086227\n",
      "0.02738090232014656\n",
      "0.11466815322637558\n",
      "0.08377791196107864\n",
      "0.02710898220539093\n",
      "0.14566706120967865\n",
      "0.08230531215667725\n",
      "0.02636026218533516\n",
      "0.13050198554992676\n",
      "0.08057721704244614\n",
      "0.026903122663497925\n",
      "0.1625225692987442\n",
      "0.0798117145895958\n",
      "0.026848094537854195\n",
      "0.10588787496089935\n",
      "0.09298597276210785\n",
      "0.026085341349244118\n",
      "0.156871497631073\n",
      "0.08469261974096298\n",
      "0.026085063815116882\n",
      "0.12117793411016464\n",
      "0.09117421507835388\n",
      "0.026966005563735962\n",
      "0.11378031969070435\n",
      "0.09125994145870209\n",
      "0.02658759616315365\n",
      "0.1195872351527214\n",
      "0.09148067235946655\n",
      "0.02615424059331417\n",
      "0.13341394066810608\n",
      "0.0953022912144661\n",
      "0.02555808611214161\n",
      "0.11362317949533463\n",
      "0.08580256998538971\n",
      "0.026213012635707855\n",
      "0.15902601182460785\n",
      "0.07996290177106857\n",
      "0.026096317917108536\n",
      "0.12438260763883591\n",
      "0.09133216738700867\n",
      "0.026258796453475952\n",
      "0.10611830651760101\n",
      "0.08242426067590714\n",
      "0.026446828618645668\n"
     ]
    }
   ],
   "source": [
    "# Training\n",
    "for epoch in range(num_epochs):\n",
    "    for i, (value,labels) in enumerate(train_dat1):\n",
    "        value = value.reshape(-1,sequence_length-4,input_size).to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        # forward pass\n",
    "        outputs = lstm_o(value)\n",
    "        loss = criterion(outputs.squeeze(),labels.squeeze())\n",
    "\n",
    "        # optimization step\n",
    "        op_o.zero_grad()\n",
    "        loss.backward()\n",
    "        op_o.step()\n",
    "\n",
    "        if i % 500 == 0:\n",
    "            print(loss.item())\n",
    "    \n",
    "    for i, (value,labels) in enumerate(train_dat2):\n",
    "        value = value.reshape(-1,sequence_length-4,input_size).to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        # forward pass\n",
    "        outputs = lstm_o(value)\n",
    "        loss = criterion(outputs.squeeze(),labels.squeeze())\n",
    "\n",
    "        # optimization step\n",
    "        op_o.zero_grad()\n",
    "        loss.backward()\n",
    "        op_o.step()\n",
    "\n",
    "        if i % 500 == 0:\n",
    "            print(loss.item())\n",
    "    \n",
    "    for i, (value,labels) in enumerate(train_dat3):\n",
    "        value = value.reshape(-1,sequence_length-4,input_size).to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        # forward pass\n",
    "        outputs = lstm_ma(value)\n",
    "        loss = criterion(outputs.squeeze(),labels.squeeze())\n",
    "\n",
    "        # optimization step\n",
    "        op_o.zero_grad()\n",
    "        loss.backward()\n",
    "        op_o.step()\n",
    "\n",
    "        if i % 500 == 0:\n",
    "            print(loss.item())\n",
    "    \n",
    "    scheduler_o.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.1064)\n",
      "0.22825231062607806\n",
      "0.9593997597694397\n",
      "0.1467757448554039\n",
      "0.5140350877192983\n"
     ]
    }
   ],
   "source": [
    "# Evaluation\n",
    "lstm_ma.eval()\n",
    "mse = 0\n",
    "i = 0\n",
    "re = np.array([])\n",
    "with torch.no_grad():\n",
    "    for values, labels in test_dat:\n",
    "        values = values.reshape(-1,sequence_length-4,input_size).to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        outputs = lstm_ma(values)\n",
    "        mse += torch.sum((outputs-labels)**2)\n",
    "        i += len(labels.flatten())\n",
    "        re_tmp = np.array(np.abs(labels.flatten()-outputs.flatten()))\n",
    "        re = np.concatenate((re,re_tmp),axis=0)\n",
    "print(mse/i)\n",
    "mean_rerror = np.mean(re)\n",
    "max_rerror = np.max(re)\n",
    "median_rerror = np.median(re)\n",
    "print(mean_rerror)\n",
    "print(max_rerror)\n",
    "print(median_rerror)\n",
    "idx = re <= 0.15\n",
    "idx = idx + 0\n",
    "print(sum(idx)/len(idx))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "ad2bdc8ecc057115af97d19610ffacc2b4e99fae6737bb82f5d7fb13d2f2c186"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
