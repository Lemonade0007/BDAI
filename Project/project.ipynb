{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#-*- coding:utf-8 -*-\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch.utils.data as data\n",
    "\n",
    "train = pd.read_csv(\"data.csv\",parse_dates=[\"Date\"])\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "wind1 = pd.read_csv(\"./dataset/wind1.csv\")\n",
    "wind2 = pd.read_csv(\"./dataset/wind2.csv\")\n",
    "wind3 = pd.read_csv(\"./dataset/wind3.csv\")\n",
    "wind4 = pd.read_csv(\"./dataset/wind4.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyper-Parameters\n",
    "sequence_length = 20\n",
    "input_size = 2\n",
    "hidden_size = 64\n",
    "num_layers = 2\n",
    "output_size = 4\n",
    "batch_size = 10\n",
    "num_epochs = 50\n",
    "learning_rate = 5e-5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class mydata(data.Dataset):\n",
    "    def __init__(self, input_dat, y,seq_length):\n",
    "        self.input_dat = torch.tensor(input_dat).float()\n",
    "        self.y = torch.tensor(y).float()\n",
    "        self.seq_length = seq_length\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if idx >= self.seq_length - 1:\n",
    "            i_start = idx - self.seq_length + 1\n",
    "            x = self.input_dat[i_start:(idx-3),:]\n",
    "            y = self.y[(idx-3):(idx+1)]\n",
    "        elif idx>=3:\n",
    "            padding = self.input_dat[0].repeat(self.seq_length-idx-1,1)\n",
    "            x = self.input_dat[0:(idx-3),:]\n",
    "            x = torch.cat((padding,x),0)\n",
    "            y = self.y[(idx-3):(idx+1)]\n",
    "        else:\n",
    "            x = self.input_dat[0].repeat(self.seq_length-4,1)\n",
    "            padding_y = self.y[0].repeat(3-idx)\n",
    "            y = self.y[0:(idx+1)]\n",
    "            y = torch.cat((padding_y,y),0)\n",
    "        return x, y\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.input_dat.shape[0]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using two strategies,\n",
    "\n",
    "1. Test using MA data and Test relative error using MA data\n",
    "2. Test using original data and test re using original data\n",
    "\n",
    "Later, I'll figure out how to test using original data\n",
    "\n",
    "Split the 4th dataset to test set and the first 3 dataset as training set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training Sets\n",
    "train1 = np.array(wind1[[\"GridPowerMA\",\"WindSpdMA\"]][19:])\n",
    "train_data1 = mydata(train1, train1[:,1], sequence_length)\n",
    "train2 = np.array(wind2[[\"GridPowerMA\",\"WindSpdMA\"]][19:])\n",
    "train_data2 = mydata(train2, train2[:,1], sequence_length)\n",
    "train3 = np.array(wind3[[\"GridPowerMA\",\"WindSpdMA\"]][19:])\n",
    "train_data3 = mydata(train3, train3[:,1], sequence_length)\n",
    "\n",
    "# Test Sets\n",
    "test = np.array(wind4[[\"GridPowerMA\",\"WindSpdMA\"]][19:])\n",
    "test_target = np.array(wind4[\"GridPower\"][19:])\n",
    "test_data = mydata(test, test_target, sequence_length)\n",
    "\n",
    "# Data Loader\n",
    "train_dat1 = data.DataLoader(dataset=train_data1, batch_size=batch_size, shuffle=True)\n",
    "train_dat2 = data.DataLoader(dataset=train_data2, batch_size=batch_size, shuffle=True)\n",
    "train_dat3 = data.DataLoader(dataset=train_data3, batch_size=batch_size, shuffle=True)\n",
    "test_dat = data.DataLoader(dataset=test_data, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Build RNN(LSTM)\n",
    "class RNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_layers, output_size):\n",
    "        super(RNN, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        self.lstm = nn.LSTM(input_size, hidden_size, num_layers, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_size,output_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # set initial hidden and cell states\n",
    "        h0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(device) \n",
    "        c0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(device)\n",
    "        \n",
    "        # Forward propagate LSTM\n",
    "        out, _ = self.lstm(x, (h0, c0))  # out: tensor of shape (batch_size, seq_length, hidden_size)\n",
    "\n",
    "        # Decode the hidden state of the last time step\n",
    "        out = self.fc(out[:, -1, :])\n",
    "        return out\n",
    "\n",
    "lstm_ma = RNN(input_size, hidden_size, num_layers, output_size).to(device)\n",
    "\n",
    "# Loss and optimizer\n",
    "criterion = nn.MSELoss()\n",
    "op_ma = torch.optim.Adam(lstm_ma.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "262.5467224121094\n",
      "165.9254150390625\n",
      "83.04984283447266\n",
      "49.47563934326172\n",
      "77.54268646240234\n",
      "102.51700592041016\n",
      "46.55242156982422\n",
      "24.033435821533203\n",
      "60.3685188293457\n",
      "63.91608810424805\n",
      "30.03835105895996\n",
      "15.727468490600586\n",
      "74.26068878173828\n",
      "104.9194107055664\n",
      "55.2623405456543\n",
      "8.25046157836914\n",
      "46.17960739135742\n",
      "28.744115829467773\n",
      "29.35824966430664\n",
      "5.904544830322266\n",
      "75.95479583740234\n",
      "53.54206085205078\n",
      "29.204265594482422\n",
      "4.59467077255249\n",
      "64.35661315917969\n",
      "60.74768829345703\n",
      "15.8454008102417\n",
      "1.7058446407318115\n",
      "28.745752334594727\n",
      "14.777170181274414\n",
      "10.747109413146973\n",
      "1.1337114572525024\n",
      "62.03737258911133\n",
      "23.258066177368164\n",
      "11.515352249145508\n",
      "1.0847610235214233\n",
      "100.46009826660156\n",
      "58.1248893737793\n",
      "8.412302017211914\n",
      "0.7505922317504883\n",
      "11.86823844909668\n",
      "19.321632385253906\n",
      "10.11913013458252\n",
      "1.4977715015411377\n",
      "26.596324920654297\n",
      "42.243324279785156\n",
      "5.154630661010742\n",
      "0.8911272287368774\n",
      "64.93714904785156\n",
      "12.156972885131836\n",
      "4.917366981506348\n",
      "1.9708070755004883\n",
      "28.999713897705078\n",
      "14.007423400878906\n",
      "4.274779319763184\n",
      "3.5680556297302246\n",
      "21.0961971282959\n",
      "15.451334953308105\n",
      "2.1083123683929443\n",
      "4.269527912139893\n",
      "26.632610321044922\n",
      "11.176045417785645\n",
      "3.9076790809631348\n",
      "0.7847496271133423\n",
      "6.299563407897949\n",
      "5.35024356842041\n",
      "1.1376588344573975\n",
      "0.10949423164129257\n",
      "18.615413665771484\n",
      "25.31882667541504\n",
      "1.412649393081665\n",
      "0.12548978626728058\n",
      "1.0544726848602295\n",
      "24.266864776611328\n",
      "2.0249688625335693\n",
      "0.06415723264217377\n",
      "1.9831594228744507\n",
      "12.326193809509277\n",
      "1.6404616832733154\n",
      "0.0925835594534874\n",
      "15.254735946655273\n",
      "18.091068267822266\n",
      "0.687120795249939\n",
      "0.04087604954838753\n",
      "1.1532148122787476\n",
      "16.315000534057617\n",
      "0.3119135797023773\n",
      "0.04863531142473221\n",
      "29.117919921875\n",
      "0.17066828906536102\n",
      "0.3992610573768616\n",
      "0.09310203790664673\n",
      "13.849896430969238\n",
      "0.23506803810596466\n",
      "1.7056939601898193\n",
      "0.04138007014989853\n",
      "10.679729461669922\n",
      "0.51118403673172\n",
      "2.158616542816162\n",
      "0.08508750796318054\n",
      "8.617219924926758\n",
      "3.027874231338501\n",
      "0.13062343001365662\n",
      "0.03666575625538826\n",
      "0.29956290125846863\n",
      "0.10790014266967773\n",
      "0.07746701687574387\n",
      "0.04617106914520264\n",
      "18.857654571533203\n",
      "12.780435562133789\n",
      "0.41018208861351013\n",
      "0.07874530553817749\n",
      "0.1932412087917328\n",
      "3.1524102687835693\n",
      "0.7008906006813049\n",
      "0.05987877771258354\n",
      "8.151461601257324\n",
      "0.12329033762216568\n",
      "0.23799927532672882\n",
      "0.024829544126987457\n",
      "4.571070671081543\n",
      "0.21435432136058807\n",
      "0.7341622114181519\n",
      "0.03771297633647919\n",
      "0.1014292985200882\n",
      "6.5249457359313965\n",
      "0.18859650194644928\n",
      "0.027463078498840332\n",
      "16.397775650024414\n",
      "1.3846728801727295\n",
      "0.17471806704998016\n",
      "0.05748413875699043\n",
      "3.3317794799804688\n",
      "7.799539089202881\n",
      "0.04695549234747887\n",
      "0.08830253779888153\n",
      "0.5821518898010254\n",
      "0.040807418525218964\n",
      "0.08490312844514847\n",
      "0.0449996143579483\n",
      "0.24173179268836975\n",
      "1.9689624309539795\n",
      "0.10589921474456787\n",
      "0.04231070354580879\n",
      "11.564745903015137\n",
      "2.0046849250793457\n",
      "0.05335051938891411\n",
      "0.08169537782669067\n",
      "0.07844705879688263\n",
      "0.05561811476945877\n",
      "0.03882106393575668\n",
      "0.04971025884151459\n",
      "34.542930603027344\n",
      "2.071704626083374\n",
      "0.02451416663825512\n",
      "0.03057835064828396\n",
      "0.07300613820552826\n",
      "9.577885627746582\n",
      "0.07871519774198532\n",
      "0.01663309521973133\n",
      "0.04958971589803696\n",
      "1.8261823654174805\n",
      "0.06508789211511612\n",
      "0.05098358541727066\n",
      "0.3424864411354065\n",
      "2.086989402770996\n",
      "0.07893960177898407\n",
      "0.029627015814185143\n",
      "8.412169456481934\n",
      "0.1232607364654541\n",
      "0.06478230655193329\n",
      "0.04078388586640358\n",
      "0.08846480399370193\n",
      "0.8777898550033569\n",
      "0.0233793705701828\n",
      "0.044370390474796295\n",
      "4.5047407150268555\n",
      "7.395175933837891\n",
      "0.05868670344352722\n",
      "0.03355448693037033\n",
      "4.594576358795166\n",
      "0.5386624932289124\n",
      "0.0420956164598465\n",
      "0.02965722605586052\n",
      "0.4324391484260559\n",
      "0.09722515195608139\n",
      "0.09321242570877075\n",
      "0.03850126266479492\n",
      "0.058142293244600296\n",
      "0.05008827522397041\n",
      "0.060587286949157715\n",
      "0.021434037014842033\n",
      "0.19600005447864532\n",
      "0.11317221820354462\n",
      "0.29233211278915405\n",
      "0.061286844313144684\n",
      "0.03408513590693474\n",
      "0.10435881465673447\n",
      "0.023751726374030113\n",
      "0.013340286910533905\n"
     ]
    }
   ],
   "source": [
    "# Training\n",
    "for epoch in range(num_epochs):\n",
    "    for i, (value,labels) in enumerate(train_dat1):\n",
    "        value = value.reshape(-1,sequence_length-4,input_size).to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        # forward pass\n",
    "        outputs = lstm_ma(value)\n",
    "        loss = criterion(outputs.squeeze(),labels.squeeze())\n",
    "\n",
    "        # optimization step\n",
    "        op_ma.zero_grad()\n",
    "        loss.backward()\n",
    "        op_ma.step()\n",
    "\n",
    "        if i % 100 == 0:\n",
    "            print(loss.item())\n",
    "    \n",
    "    for i, (value,labels) in enumerate(train_dat2):\n",
    "        value = value.reshape(-1,sequence_length-4,input_size).to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        # forward pass\n",
    "        outputs = lstm_ma(value)\n",
    "        loss = criterion(outputs.squeeze(),labels.squeeze())\n",
    "\n",
    "        # optimization step\n",
    "        op_ma.zero_grad()\n",
    "        loss.backward()\n",
    "        op_ma.step()\n",
    "\n",
    "        if i % 100 == 0:\n",
    "            print(loss.item())\n",
    "    \n",
    "    for i, (value,labels) in enumerate(train_dat3):\n",
    "        value = value.reshape(-1,sequence_length-4,input_size).to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        # forward pass\n",
    "        outputs = lstm_ma(value)\n",
    "        loss = criterion(outputs.squeeze(),labels.squeeze())\n",
    "\n",
    "        # optimization step\n",
    "        op_ma.zero_grad()\n",
    "        loss.backward()\n",
    "        op_ma.step()\n",
    "\n",
    "        if i % 100 == 0:\n",
    "            print(loss.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.6128)\n",
      "0.3128629867047589\n",
      "1.3585950136184692\n",
      "0.3038007318973541\n",
      "0.2614035087719298\n"
     ]
    }
   ],
   "source": [
    "# Evaluation\n",
    "lstm_ma.eval()\n",
    "mse = 0\n",
    "i = 0\n",
    "re = np.array([])\n",
    "with torch.no_grad():\n",
    "    for values, labels in test_dat:\n",
    "        values = values.reshape(-1,sequence_length-4,input_size).to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        outputs = lstm_ma(values)\n",
    "        mse += torch.sum((outputs/15-labels/15)**2)\n",
    "        i += len(labels)\n",
    "        re_tmp = np.array(np.abs(labels.flatten()-outputs.flatten())/15)\n",
    "        re = np.concatenate((re,re_tmp),axis=0)\n",
    "print(mse/i)\n",
    "mean_rerror = np.mean(re)\n",
    "max_rerror = np.max(re)\n",
    "median_rerror = np.median(re)\n",
    "print(mean_rerror)\n",
    "print(max_rerror)\n",
    "print(median_rerror)\n",
    "idx = re <= 0.15\n",
    "idx = idx + 0\n",
    "print(sum(idx)/len(idx))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "ad2bdc8ecc057115af97d19610ffacc2b4e99fae6737bb82f5d7fb13d2f2c186"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
