{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#-*- coding:utf-8 -*-\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch.utils.data as data\n",
    "\n",
    "train = pd.read_csv(\"data.csv\",parse_dates=[\"Date\"])\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "wind1 = pd.read_csv(\"./dataset/wind1.csv\")\n",
    "wind2 = pd.read_csv(\"./dataset/wind2.csv\")\n",
    "wind3 = pd.read_csv(\"./dataset/wind3.csv\")\n",
    "wind4 = pd.read_csv(\"./dataset/wind4.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.optim.lr_scheduler import ExponentialLR\n",
    "\n",
    "# Hyper-Parameters\n",
    "sequence_length = 36\n",
    "input_size = 2\n",
    "hidden_size = 64\n",
    "num_layers = 3\n",
    "output_size = 4\n",
    "batch_size = 64\n",
    "num_epochs = 32\n",
    "learning_rate = 1e-5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "class mydata(data.Dataset):\n",
    "    def __init__(self, input_dat, y,seq_length):\n",
    "        self.input_dat = torch.tensor(input_dat).float()\n",
    "        self.y = torch.tensor(y).float()\n",
    "        self.seq_length = seq_length\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if idx >= self.seq_length - 1:\n",
    "            i_start = idx - self.seq_length + 1\n",
    "            x = self.input_dat[i_start:(idx-3),:]\n",
    "            y = self.y[(idx-3):(idx+1)]\n",
    "        elif idx>=3:\n",
    "            padding = self.input_dat[0].repeat(self.seq_length-idx-1,1)\n",
    "            x = self.input_dat[0:(idx-3),:]\n",
    "            x = torch.cat((padding,x),0)\n",
    "            y = self.y[(idx-3):(idx+1)]\n",
    "        else:\n",
    "            x = self.input_dat[0].repeat(self.seq_length-4,1)\n",
    "            padding_y = self.y[0].repeat(3-idx)\n",
    "            y = self.y[0:(idx+1)]\n",
    "            y = torch.cat((padding_y,y),0)\n",
    "        return x, y\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.input_dat.shape[0]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using two strategies,\n",
    "\n",
    "1. Test using MA data and Test relative error using MA data\n",
    "2. Test using original data and test re using original data\n",
    "\n",
    "Later, I'll figure out how to test using original data\n",
    "\n",
    "Split the 4th dataset to test set and the first 3 dataset as training set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training Sets\n",
    "train1 = np.array(wind1[[\"GridPowerMA\",\"WindSpdMA\"]][19:])\n",
    "train_data1 = mydata(train1, train1[:,1], sequence_length)\n",
    "train2 = np.array(wind2[[\"GridPowerMA\",\"WindSpdMA\"]][19:])\n",
    "train_data2 = mydata(train2, train2[:,1], sequence_length)\n",
    "train3 = np.array(wind3[[\"GridPowerMA\",\"WindSpdMA\"]][19:])\n",
    "train_data3 = mydata(train3, train3[:,1], sequence_length)\n",
    "\n",
    "# Test Sets\n",
    "test = np.array(wind4[[\"GridPowerMA\",\"WindSpdMA\"]][19:])\n",
    "test_target = np.array(wind4[\"GridPower\"][19:])\n",
    "test_data = mydata(test, test_target, sequence_length)\n",
    "test_data1 = mydata(test,test[:,1],sequence_length)\n",
    "\n",
    "# Data Loader\n",
    "train_dat1 = data.DataLoader(dataset=train_data1, batch_size=batch_size, shuffle=True)\n",
    "train_dat2 = data.DataLoader(dataset=train_data2, batch_size=batch_size, shuffle=True)\n",
    "train_dat3 = data.DataLoader(dataset=train_data3, batch_size=batch_size, shuffle=True)\n",
    "test_dat = data.DataLoader(dataset=test_data, batch_size=batch_size, shuffle=True)\n",
    "test_dat1 = data.DataLoader(dataset=test_data1, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Build RNN(LSTM)\n",
    "class RNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_layers, output_size):\n",
    "        super(RNN, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        self.lstm = nn.LSTM(input_size, hidden_size, num_layers, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_size,output_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # set initial hidden and cell states\n",
    "        h0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(device) \n",
    "        c0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(device)\n",
    "        \n",
    "        # Forward propagate LSTM\n",
    "        out, _ = self.lstm(x, (h0, c0))  # out: tensor of shape (batch_size, seq_length, hidden_size)\n",
    "\n",
    "        # Decode the hidden state of the last time step\n",
    "        out = self.fc(out[:, -1, :])\n",
    "        return out\n",
    "\n",
    "lstm_ma = RNN(input_size, hidden_size, num_layers, output_size).to(device)\n",
    "lstm_o = RNN(input_size,hidden_size, num_layers, output_size).to(device)\n",
    "\n",
    "# Loss and optimizer\n",
    "criterion = nn.MSELoss()\n",
    "op_ma = torch.optim.Adam(lstm_ma.parameters(), lr=learning_rate)\n",
    "op_o = torch.optim.Adam(lstm_ma.parameters(), lr=learning_rate)\n",
    "scheduler_ma = ExponentialLR(op_ma,gamma=0.9)\n",
    "scheduler_o = ExponentialLR(op_o,gamma=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.23247407376766205\n",
      "0.1668686419725418\n",
      "0.10178763419389725\n",
      "0.19379261136054993\n",
      "0.168056458234787\n",
      "0.09829328954219818\n",
      "0.2280089110136032\n",
      "0.12944704294204712\n",
      "0.09611589461565018\n",
      "0.20459991693496704\n",
      "0.16024570167064667\n",
      "0.09389175474643707\n",
      "0.20289510488510132\n",
      "0.13519279658794403\n",
      "0.09103573858737946\n",
      "0.195567786693573\n",
      "0.13120624423027039\n",
      "0.0902961790561676\n",
      "0.18834760785102844\n",
      "0.13051503896713257\n",
      "0.08765137195587158\n",
      "0.22784999012947083\n",
      "0.1272963434457779\n",
      "0.08554662764072418\n",
      "0.1880972534418106\n",
      "0.1319674253463745\n",
      "0.0844850167632103\n",
      "0.17595909535884857\n",
      "0.1327458620071411\n",
      "0.08339233696460724\n",
      "0.17157359421253204\n",
      "0.12328625470399857\n",
      "0.07940793037414551\n",
      "0.16686026751995087\n",
      "0.12831765413284302\n",
      "0.07961888611316681\n",
      "0.21523205935955048\n",
      "0.1271696835756302\n",
      "0.07895112782716751\n",
      "0.16976554691791534\n",
      "0.1163848340511322\n",
      "0.07773329317569733\n",
      "0.1579831838607788\n",
      "0.11638255417346954\n",
      "0.07796187698841095\n",
      "0.19742295145988464\n",
      "0.12467637658119202\n",
      "0.07739713042974472\n",
      "0.16481447219848633\n",
      "0.11793337762355804\n",
      "0.07620110362768173\n",
      "0.17108985781669617\n",
      "0.12180303037166595\n",
      "0.07526487112045288\n",
      "0.16107851266860962\n",
      "0.12025290727615356\n",
      "0.0734517052769661\n",
      "0.1955653429031372\n",
      "0.12288207560777664\n",
      "0.0736209973692894\n",
      "0.16164793074131012\n",
      "0.11284124106168747\n",
      "0.07260121405124664\n",
      "0.17836259305477142\n",
      "0.126662015914917\n",
      "0.07239106297492981\n",
      "0.181623175740242\n",
      "0.10819293558597565\n",
      "0.07102624326944351\n",
      "0.17312370240688324\n",
      "0.12363381683826447\n",
      "0.0727628767490387\n",
      "0.13741491734981537\n",
      "0.11351320892572403\n",
      "0.07057825475931168\n",
      "0.19326892495155334\n",
      "0.11444556713104248\n",
      "0.07127747684717178\n",
      "0.16318979859352112\n",
      "0.10407979786396027\n",
      "0.07157651335000992\n",
      "0.18269874155521393\n",
      "0.1195078045129776\n",
      "0.07077249884605408\n",
      "0.13893276453018188\n",
      "0.10875709354877472\n",
      "0.06956837326288223\n",
      "0.14564169943332672\n",
      "0.12300072610378265\n",
      "0.06990456581115723\n",
      "0.12782512605190277\n",
      "0.11179357767105103\n",
      "0.07098247855901718\n",
      "0.1584339737892151\n",
      "0.11039337515830994\n",
      "0.06960947066545486\n"
     ]
    }
   ],
   "source": [
    "# Training\n",
    "for epoch in range(num_epochs):\n",
    "    for i, (value,labels) in enumerate(train_dat1):\n",
    "        value = value.reshape(-1,sequence_length-4,input_size).to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        # forward pass\n",
    "        outputs = lstm_ma(value)\n",
    "        loss = criterion(outputs.squeeze(),labels.squeeze())\n",
    "\n",
    "        # optimization step\n",
    "        op_ma.zero_grad()\n",
    "        loss.backward()\n",
    "        op_ma.step()\n",
    "\n",
    "        if i % 500 == 0:\n",
    "            print(loss.item())\n",
    "    \n",
    "    for i, (value,labels) in enumerate(train_dat2):\n",
    "        value = value.reshape(-1,sequence_length-4,input_size).to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        # forward pass\n",
    "        outputs = lstm_ma(value)\n",
    "        loss = criterion(outputs.squeeze(),labels.squeeze())\n",
    "\n",
    "        # optimization step\n",
    "        op_ma.zero_grad()\n",
    "        loss.backward()\n",
    "        op_ma.step()\n",
    "\n",
    "        if i % 500 == 0:\n",
    "            print(loss.item())\n",
    "    \n",
    "    for i, (value,labels) in enumerate(train_dat3):\n",
    "        value = value.reshape(-1,sequence_length-4,input_size).to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        # forward pass\n",
    "        outputs = lstm_ma(value)\n",
    "        loss = criterion(outputs.squeeze(),labels.squeeze())\n",
    "\n",
    "        # optimization step\n",
    "        op_ma.zero_grad()\n",
    "        loss.backward()\n",
    "        op_ma.step()\n",
    "\n",
    "        if i % 500 == 0:\n",
    "            print(loss.item())\n",
    "    \n",
    "    scheduler_ma.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.1590)\n",
      "0.29496159076306705\n",
      "1.038631796836853\n",
      "0.22426925599575043\n",
      "0.3798245614035088\n"
     ]
    }
   ],
   "source": [
    "# Evaluation\n",
    "lstm_ma.eval()\n",
    "mse = 0\n",
    "i = 0\n",
    "re = np.array([])\n",
    "with torch.no_grad():\n",
    "    for values, labels in test_dat:\n",
    "        values = values.reshape(-1,sequence_length-4,input_size).to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        outputs = lstm_ma(values)\n",
    "        mse += torch.sum((outputs-labels)**2)\n",
    "        i += len(labels.flatten())\n",
    "        re_tmp = np.array(np.abs(labels.flatten()-outputs.flatten()))\n",
    "        re = np.concatenate((re,re_tmp),axis=0)\n",
    "print(mse/i)\n",
    "mean_rerror = np.mean(re)\n",
    "max_rerror = np.max(re)\n",
    "median_rerror = np.median(re)\n",
    "print(mean_rerror)\n",
    "print(max_rerror)\n",
    "print(median_rerror)\n",
    "idx = re <= 0.15\n",
    "idx = idx + 0\n",
    "print(sum(idx)/len(idx))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.1182)\n",
      "0.32495330091761915\n",
      "0.6254315376281738\n",
      "0.3184541016817093\n",
      "0.043859649122807015\n"
     ]
    }
   ],
   "source": [
    "# Evaluation using ma data\n",
    "lstm_ma.eval()\n",
    "mse = 0\n",
    "i = 0\n",
    "re = np.array([])\n",
    "with torch.no_grad():\n",
    "    for values, labels in test_dat1:\n",
    "        values = values.reshape(-1,sequence_length-4,input_size).to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        outputs = lstm_ma(values)\n",
    "        mse += torch.sum((outputs-labels)**2)\n",
    "        i += len(labels.flatten())\n",
    "        re_tmp = np.array(np.abs(labels.flatten()-outputs.flatten()))\n",
    "        re = np.concatenate((re,re_tmp),axis=0)\n",
    "print(mse/i)\n",
    "mean_rerror = np.mean(re)\n",
    "max_rerror = np.max(re)\n",
    "median_rerror = np.median(re)\n",
    "print(mean_rerror)\n",
    "print(max_rerror)\n",
    "print(median_rerror)\n",
    "idx = re <= 0.15\n",
    "idx = idx + 0\n",
    "print(sum(idx)/len(idx))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If just input the original data, let's see what will happen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training Sets\n",
    "train1 = np.array(wind1[[\"GridPower\",\"WindSpd\"]][19:])\n",
    "train_data1 = mydata(train1, train1[:,1], sequence_length)\n",
    "train2 = np.array(wind2[[\"GridPower\",\"WindSpdMA\"]][19:])\n",
    "train_data2 = mydata(train2, train2[:,1], sequence_length)\n",
    "train3 = np.array(wind3[[\"GridPower\",\"WindSpd\"]][19:])\n",
    "train_data3 = mydata(train3, train3[:,1], sequence_length)\n",
    "\n",
    "# Data Loader\n",
    "train_dat1 = data.DataLoader(dataset=train_data1, batch_size=batch_size, shuffle=True)\n",
    "train_dat2 = data.DataLoader(dataset=train_data2, batch_size=batch_size, shuffle=True)\n",
    "train_dat3 = data.DataLoader(dataset=train_data3, batch_size=batch_size, shuffle=True)\n",
    "test_dat = data.DataLoader(dataset=test_data, batch_size=batch_size, shuffle=True)\n",
    "test_dat1 = data.DataLoader(dataset=test_data1, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.15396609902381897\n",
      "0.12202358990907669\n",
      "0.07212130725383759\n",
      "0.1529170274734497\n",
      "0.12267377972602844\n",
      "0.07155870646238327\n",
      "0.18338389694690704\n",
      "0.13738606870174408\n",
      "0.0696970745921135\n",
      "0.18831761181354523\n",
      "0.15084999799728394\n",
      "0.07218291610479355\n",
      "0.17475491762161255\n",
      "0.12089580297470093\n",
      "0.06876976788043976\n",
      "0.18361428380012512\n",
      "0.140211284160614\n",
      "0.06818101555109024\n",
      "0.1825834959745407\n",
      "0.13150930404663086\n",
      "0.06813901662826538\n",
      "0.1979655623435974\n",
      "0.12256109714508057\n",
      "0.06794748455286026\n",
      "0.16829614341259003\n",
      "0.13042856752872467\n",
      "0.06849399209022522\n",
      "0.17424876987934113\n",
      "0.1392582654953003\n",
      "0.06697522848844528\n",
      "0.17762917280197144\n",
      "0.1249767318367958\n",
      "0.06696401536464691\n",
      "0.17472949624061584\n",
      "0.11461129039525986\n",
      "0.06643486768007278\n",
      "0.19976477324962616\n",
      "0.1246166080236435\n",
      "0.06656629592180252\n",
      "0.18946950137615204\n",
      "0.13378331065177917\n",
      "0.06606850028038025\n",
      "0.18713048100471497\n",
      "0.11377917975187302\n",
      "0.0667945146560669\n",
      "0.17057552933692932\n",
      "0.12270572781562805\n",
      "0.06652942299842834\n",
      "0.17585238814353943\n",
      "0.12238942831754684\n",
      "0.06427181512117386\n",
      "0.17255637049674988\n",
      "0.1271083801984787\n",
      "0.06506934762001038\n",
      "0.17007195949554443\n",
      "0.11984796822071075\n",
      "0.0669882521033287\n",
      "0.199795201420784\n",
      "0.1264750063419342\n",
      "0.06433182954788208\n",
      "0.16832053661346436\n",
      "0.11938654631376266\n",
      "0.06582511216402054\n",
      "0.18806330859661102\n",
      "0.14290708303451538\n",
      "0.06526761502027512\n",
      "0.16187694668769836\n",
      "0.12729512155056\n",
      "0.06499097496271133\n",
      "0.17959897220134735\n",
      "0.12492340058088303\n",
      "0.0635470449924469\n",
      "0.18251098692417145\n",
      "0.12156160175800323\n",
      "0.06349687278270721\n",
      "0.1706673800945282\n",
      "0.14274302124977112\n",
      "0.06426790356636047\n",
      "0.18097279965877533\n",
      "0.13805702328681946\n",
      "0.06320606172084808\n",
      "0.17908994853496552\n",
      "0.1292334496974945\n",
      "0.06463290005922318\n",
      "0.19746984541416168\n",
      "0.1276901215314865\n",
      "0.06349697709083557\n",
      "0.1834588497877121\n",
      "0.12669679522514343\n",
      "0.06434424966573715\n",
      "0.17170894145965576\n",
      "0.12698693573474884\n",
      "0.06352414190769196\n",
      "0.15707743167877197\n",
      "0.12166140973567963\n",
      "0.06441957503557205\n"
     ]
    }
   ],
   "source": [
    "# Training\n",
    "for epoch in range(num_epochs):\n",
    "    for i, (value,labels) in enumerate(train_dat1):\n",
    "        value = value.reshape(-1,sequence_length-4,input_size).to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        # forward pass\n",
    "        outputs = lstm_o(value)\n",
    "        loss = criterion(outputs.squeeze(),labels.squeeze())\n",
    "\n",
    "        # optimization step\n",
    "        op_o.zero_grad()\n",
    "        loss.backward()\n",
    "        op_o.step()\n",
    "\n",
    "        if i % 500 == 0:\n",
    "            print(loss.item())\n",
    "    \n",
    "    for i, (value,labels) in enumerate(train_dat2):\n",
    "        value = value.reshape(-1,sequence_length-4,input_size).to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        # forward pass\n",
    "        outputs = lstm_o(value)\n",
    "        loss = criterion(outputs.squeeze(),labels.squeeze())\n",
    "\n",
    "        # optimization step\n",
    "        op_o.zero_grad()\n",
    "        loss.backward()\n",
    "        op_o.step()\n",
    "\n",
    "        if i % 500 == 0:\n",
    "            print(loss.item())\n",
    "    \n",
    "    for i, (value,labels) in enumerate(train_dat3):\n",
    "        value = value.reshape(-1,sequence_length-4,input_size).to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        # forward pass\n",
    "        outputs = lstm_ma(value)\n",
    "        loss = criterion(outputs.squeeze(),labels.squeeze())\n",
    "\n",
    "        # optimization step\n",
    "        op_o.zero_grad()\n",
    "        loss.backward()\n",
    "        op_o.step()\n",
    "\n",
    "        if i % 500 == 0:\n",
    "            print(loss.item())\n",
    "    \n",
    "    scheduler_o.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.1494)\n",
      "0.28150312708805136\n",
      "1.0250438451766968\n",
      "0.2079901546239853\n",
      "0.4070175438596491\n"
     ]
    }
   ],
   "source": [
    "# Evaluation\n",
    "lstm_ma.eval()\n",
    "mse = 0\n",
    "i = 0\n",
    "re = np.array([])\n",
    "with torch.no_grad():\n",
    "    for values, labels in test_dat:\n",
    "        values = values.reshape(-1,sequence_length-4,input_size).to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        outputs = lstm_ma(values)\n",
    "        mse += torch.sum((outputs-labels)**2)\n",
    "        i += len(labels.flatten())\n",
    "        re_tmp = np.array(np.abs(labels.flatten()-outputs.flatten()))\n",
    "        re = np.concatenate((re,re_tmp),axis=0)\n",
    "print(mse/i)\n",
    "mean_rerror = np.mean(re)\n",
    "max_rerror = np.max(re)\n",
    "median_rerror = np.median(re)\n",
    "print(mean_rerror)\n",
    "print(max_rerror)\n",
    "print(median_rerror)\n",
    "idx = re <= 0.15\n",
    "idx = idx + 0\n",
    "print(sum(idx)/len(idx))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "ad2bdc8ecc057115af97d19610ffacc2b4e99fae6737bb82f5d7fb13d2f2c186"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
