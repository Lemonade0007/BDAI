{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "#-*- coding:utf-8 -*-\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch.utils.data as data\n",
    "\n",
    "train = pd.read_csv(\"data.csv\",parse_dates=[\"Date\"])\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "wind1 = pd.read_csv(\"./dataset/wind1.csv\")\n",
    "wind2 = pd.read_csv(\"./dataset/wind2.csv\")\n",
    "wind3 = pd.read_csv(\"./dataset/wind3.csv\")\n",
    "wind4 = pd.read_csv(\"./dataset/wind4.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.optim.lr_scheduler import ExponentialLR\n",
    "\n",
    "# Hyper-Parameters\n",
    "sequence_length = 36\n",
    "input_size = 2\n",
    "hidden_size = 64\n",
    "num_layers = 3\n",
    "output_size = 4\n",
    "batch_size = 64\n",
    "num_epochs = 32\n",
    "learning_rate = 1e-5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "class mydata(data.Dataset):\n",
    "    def __init__(self, input_dat, y,seq_length):\n",
    "        self.input_dat = torch.tensor(input_dat).float()\n",
    "        self.y = torch.tensor(y).float()\n",
    "        self.seq_length = seq_length\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if idx >= self.seq_length - 1:\n",
    "            i_start = idx - self.seq_length + 1\n",
    "            x = self.input_dat[i_start:(idx-3),:]\n",
    "            y = self.y[(idx-3):(idx+1)]\n",
    "        elif idx>=3:\n",
    "            padding = self.input_dat[0].repeat(self.seq_length-idx-1,1)\n",
    "            x = self.input_dat[0:(idx-3),:]\n",
    "            x = torch.cat((padding,x),0)\n",
    "            y = self.y[(idx-3):(idx+1)]\n",
    "        else:\n",
    "            x = self.input_dat[0].repeat(self.seq_length-4,1)\n",
    "            padding_y = self.y[0].repeat(3-idx)\n",
    "            y = self.y[0:(idx+1)]\n",
    "            y = torch.cat((padding_y,y),0)\n",
    "        return x, y\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.input_dat.shape[0]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using two strategies,\n",
    "\n",
    "1. Test using MA data and Test relative error using MA data\n",
    "2. Test using original data and test re using original data\n",
    "\n",
    "Later, I'll figure out how to test using original data\n",
    "\n",
    "Split the 4th dataset to test set and the first 3 dataset as training set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training Sets\n",
    "train1 = np.array(wind1[[\"GridPowerMA\",\"WindSpdMA\"]][19:])\n",
    "train_data1 = mydata(train1, train1[:,1], sequence_length)\n",
    "train2 = np.array(wind2[[\"GridPowerMA\",\"WindSpdMA\"]][19:])\n",
    "train_data2 = mydata(train2, train2[:,1], sequence_length)\n",
    "train3 = np.array(wind3[[\"GridPowerMA\",\"WindSpdMA\"]][19:])\n",
    "train_data3 = mydata(train3, train3[:,1], sequence_length)\n",
    "\n",
    "# Test Sets\n",
    "test = np.array(wind4[[\"GridPowerMA\",\"WindSpdMA\"]][19:])\n",
    "test_target = np.array(wind4[\"GridPower\"][19:])\n",
    "test_data = mydata(test, test_target, sequence_length)\n",
    "test_data1 = mydata(test,test[:,1],sequence_length)\n",
    "\n",
    "# Data Loader\n",
    "train_dat1 = data.DataLoader(dataset=train_data1, batch_size=batch_size, shuffle=True)\n",
    "train_dat2 = data.DataLoader(dataset=train_data2, batch_size=batch_size, shuffle=True)\n",
    "train_dat3 = data.DataLoader(dataset=train_data3, batch_size=batch_size, shuffle=True)\n",
    "test_dat = data.DataLoader(dataset=test_data, batch_size=batch_size, shuffle=True)\n",
    "test_dat1 = data.DataLoader(dataset=test_data1, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Build RNN(LSTM)\n",
    "class RNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_layers, output_size):\n",
    "        super(RNN, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        self.lstm = nn.LSTM(input_size, hidden_size, num_layers, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_size,output_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # set initial hidden and cell states\n",
    "        h0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(device) \n",
    "        c0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(device)\n",
    "        \n",
    "        # Forward propagate LSTM\n",
    "        out, _ = self.lstm(x, (h0, c0))  # out: tensor of shape (batch_size, seq_length, hidden_size)\n",
    "\n",
    "        # Decode the hidden state of the last time step\n",
    "        out = self.fc(out[:, -1, :])\n",
    "        return out\n",
    "\n",
    "lstm_ma = RNN(input_size, hidden_size, num_layers, output_size).to(device)\n",
    "lstm_o = RNN(input_size,hidden_size, num_layers, output_size).to(device)\n",
    "\n",
    "# Loss and optimizer\n",
    "criterion = nn.MSELoss()\n",
    "op_ma = torch.optim.Adam(lstm_ma.parameters(), lr=learning_rate)\n",
    "op_o = torch.optim.Adam(lstm_ma.parameters(), lr=learning_rate)\n",
    "scheduler_ma = ExponentialLR(op_ma,gamma=0.9)\n",
    "scheduler_o = ExponentialLR(op_o,gamma=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.12503021955490112\n",
      "0.07127312570810318\n",
      "0.03707216680049896\n",
      "0.11722496151924133\n",
      "0.07402026653289795\n",
      "0.03522725775837898\n",
      "0.11703823506832123\n",
      "0.0683155283331871\n",
      "0.03375053405761719\n",
      "0.10736389458179474\n",
      "0.06292068958282471\n",
      "0.0316426046192646\n",
      "0.11460758000612259\n",
      "0.05641068518161774\n",
      "0.030776571482419968\n",
      "0.0976174846291542\n",
      "0.05728388577699661\n",
      "0.03062061220407486\n",
      "0.10358235239982605\n",
      "0.06373921036720276\n",
      "0.029408881440758705\n",
      "0.09177130460739136\n",
      "0.06415273994207382\n",
      "0.028174199163913727\n",
      "0.08733763545751572\n",
      "0.05317838862538338\n",
      "0.027636509388685226\n",
      "0.08726654201745987\n",
      "0.05572456866502762\n",
      "0.027044255286455154\n",
      "0.09670809656381607\n",
      "0.05952068790793419\n",
      "0.026229267939925194\n",
      "0.11329503357410431\n",
      "0.06489556282758713\n",
      "0.025895781815052032\n",
      "0.08331383019685745\n",
      "0.05962013825774193\n",
      "0.02497721277177334\n",
      "0.08294116705656052\n",
      "0.05752996355295181\n",
      "0.024814685806632042\n",
      "0.1025303304195404\n",
      "0.04091200232505798\n",
      "0.02418317273259163\n",
      "0.1038050651550293\n",
      "0.04930054396390915\n",
      "0.023855863139033318\n",
      "0.0776551142334938\n",
      "0.05024063587188721\n",
      "0.024078546091914177\n",
      "0.07728803902864456\n",
      "0.047250837087631226\n",
      "0.023367013782262802\n",
      "0.09302936494350433\n",
      "0.049339376389980316\n",
      "0.022513732314109802\n",
      "0.10097803920507431\n",
      "0.05046675354242325\n",
      "0.022396771237254143\n",
      "0.09396855533123016\n",
      "0.05293552950024605\n",
      "0.021782465279102325\n",
      "0.09988203644752502\n",
      "0.050588686019182205\n",
      "0.021998250856995583\n",
      "0.061743542551994324\n",
      "0.05127433314919472\n",
      "0.021239755675196648\n",
      "0.08782975375652313\n",
      "0.047363631427288055\n",
      "0.021381335332989693\n",
      "0.06282174587249756\n",
      "0.05260157585144043\n",
      "0.02082805708050728\n",
      "0.0700412318110466\n",
      "0.05215708166360855\n",
      "0.02083549275994301\n",
      "0.07101044803857803\n",
      "0.04028066247701645\n",
      "0.02087090164422989\n",
      "0.0810864269733429\n",
      "0.049113109707832336\n",
      "0.021069977432489395\n",
      "0.09302202612161636\n",
      "0.04818037897348404\n",
      "0.02017883211374283\n",
      "0.0742933601140976\n",
      "0.050552062690258026\n",
      "0.020767780020833015\n",
      "0.07926321029663086\n",
      "0.042968422174453735\n",
      "0.020907418802380562\n",
      "0.08741927146911621\n",
      "0.05239855870604515\n",
      "0.02112727425992489\n"
     ]
    }
   ],
   "source": [
    "# Training\n",
    "for epoch in range(num_epochs):\n",
    "    for i, (value,labels) in enumerate(train_dat1):\n",
    "        value = value.reshape(-1,sequence_length-4,input_size).to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        # forward pass\n",
    "        outputs = lstm_ma(value)\n",
    "        loss = criterion(outputs.squeeze(),labels.squeeze())\n",
    "\n",
    "        # optimization step\n",
    "        op_ma.zero_grad()\n",
    "        loss.backward()\n",
    "        op_ma.step()\n",
    "\n",
    "        if i % 500 == 0:\n",
    "            print(loss.item())\n",
    "    \n",
    "    for i, (value,labels) in enumerate(train_dat2):\n",
    "        value = value.reshape(-1,sequence_length-4,input_size).to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        # forward pass\n",
    "        outputs = lstm_ma(value)\n",
    "        loss = criterion(outputs.squeeze(),labels.squeeze())\n",
    "\n",
    "        # optimization step\n",
    "        op_ma.zero_grad()\n",
    "        loss.backward()\n",
    "        op_ma.step()\n",
    "\n",
    "        if i % 500 == 0:\n",
    "            print(loss.item())\n",
    "    \n",
    "    for i, (value,labels) in enumerate(train_dat3):\n",
    "        value = value.reshape(-1,sequence_length-4,input_size).to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        # forward pass\n",
    "        outputs = lstm_ma(value)\n",
    "        loss = criterion(outputs.squeeze(),labels.squeeze())\n",
    "\n",
    "        # optimization step\n",
    "        op_ma.zero_grad()\n",
    "        loss.backward()\n",
    "        op_ma.step()\n",
    "\n",
    "        if i % 500 == 0:\n",
    "            print(loss.item())\n",
    "    \n",
    "    scheduler_ma.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.1020)\n",
      "0.22163539127887863\n",
      "0.8823466300964355\n",
      "0.12902525812387466\n",
      "0.5421052631578948\n"
     ]
    }
   ],
   "source": [
    "# Evaluation\n",
    "lstm_ma.eval()\n",
    "mse = 0\n",
    "i = 0\n",
    "re = np.array([])\n",
    "with torch.no_grad():\n",
    "    for values, labels in test_dat:\n",
    "        values = values.reshape(-1,sequence_length-4,input_size).to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        outputs = lstm_ma(values)\n",
    "        mse += torch.sum((outputs-labels)**2)\n",
    "        i += len(labels.flatten())\n",
    "        re_tmp = np.array(np.abs(labels.flatten()-outputs.flatten()))\n",
    "        re = np.concatenate((re,re_tmp),axis=0)\n",
    "print(mse/i)\n",
    "mean_rerror = np.mean(re)\n",
    "max_rerror = np.max(re)\n",
    "median_rerror = np.median(re)\n",
    "print(mean_rerror)\n",
    "print(max_rerror)\n",
    "print(median_rerror)\n",
    "idx = re <= 0.15\n",
    "idx = idx + 0\n",
    "print(sum(idx)/len(idx))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0521)\n",
      "0.20058923657133915\n",
      "0.4693530201911926\n",
      "0.1804942712187767\n",
      "0.32719298245614037\n"
     ]
    }
   ],
   "source": [
    "# Evaluation using ma data\n",
    "lstm_ma.eval()\n",
    "mse = 0\n",
    "i = 0\n",
    "re = np.array([])\n",
    "with torch.no_grad():\n",
    "    for values, labels in test_dat1:\n",
    "        values = values.reshape(-1,sequence_length-4,input_size).to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        outputs = lstm_ma(values)\n",
    "        mse += torch.sum((outputs-labels)**2)\n",
    "        i += len(labels.flatten())\n",
    "        re_tmp = np.array(np.abs(labels.flatten()-outputs.flatten()))\n",
    "        re = np.concatenate((re,re_tmp),axis=0)\n",
    "print(mse/i)\n",
    "mean_rerror = np.mean(re)\n",
    "max_rerror = np.max(re)\n",
    "median_rerror = np.median(re)\n",
    "print(mean_rerror)\n",
    "print(max_rerror)\n",
    "print(median_rerror)\n",
    "idx = re <= 0.15\n",
    "idx = idx + 0\n",
    "print(sum(idx)/len(idx))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If just input the original data, let's see what will happen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training Sets\n",
    "train1 = np.array(wind1[[\"GridPower\",\"WindSpd\"]][19:])\n",
    "train_data1 = mydata(train1, train1[:,1], sequence_length)\n",
    "train2 = np.array(wind2[[\"GridPower\",\"WindSpdMA\"]][19:])\n",
    "train_data2 = mydata(train2, train2[:,1], sequence_length)\n",
    "train3 = np.array(wind3[[\"GridPower\",\"WindSpd\"]][19:])\n",
    "train_data3 = mydata(train3, train3[:,1], sequence_length)\n",
    "\n",
    "# Data Loader\n",
    "train_dat1 = data.DataLoader(dataset=train_data1, batch_size=batch_size, shuffle=True)\n",
    "train_dat2 = data.DataLoader(dataset=train_data2, batch_size=batch_size, shuffle=True)\n",
    "train_dat3 = data.DataLoader(dataset=train_data3, batch_size=batch_size, shuffle=True)\n",
    "test_dat = data.DataLoader(dataset=test_data, batch_size=batch_size, shuffle=True)\n",
    "test_dat1 = data.DataLoader(dataset=test_data1, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.154197096824646\n",
      "0.10565153509378433\n",
      "0.02195463888347149\n",
      "0.15748901665210724\n",
      "0.10910704731941223\n",
      "0.021627314388751984\n",
      "0.1565721035003662\n",
      "0.11199020594358444\n",
      "0.02053685672581196\n",
      "0.16052286326885223\n",
      "0.11380713433027267\n",
      "0.02082657441496849\n",
      "0.16602349281311035\n",
      "0.09990153461694717\n",
      "0.02042916975915432\n",
      "0.13454173505306244\n",
      "0.08956239372491837\n",
      "0.019922997802495956\n",
      "0.14994120597839355\n",
      "0.1090225800871849\n",
      "0.02024572528898716\n",
      "0.11751076579093933\n",
      "0.10660703480243683\n",
      "0.020194604992866516\n",
      "0.14819836616516113\n",
      "0.11515503376722336\n",
      "0.01932639628648758\n",
      "0.16899263858795166\n",
      "0.11235499382019043\n",
      "0.01968166045844555\n",
      "0.1738917976617813\n",
      "0.09745821356773376\n",
      "0.01966996304690838\n",
      "0.1491565704345703\n",
      "0.10136004537343979\n",
      "0.019439492374658585\n",
      "0.16803646087646484\n",
      "0.09872017800807953\n",
      "0.018883969634771347\n",
      "0.14039810001850128\n",
      "0.1152818500995636\n",
      "0.018544567748904228\n",
      "0.16711950302124023\n",
      "0.10878886282444\n",
      "0.01796245202422142\n",
      "0.17332381010055542\n",
      "0.1109936535358429\n",
      "0.018340054899454117\n",
      "0.1455560028553009\n",
      "0.10605756938457489\n",
      "0.01775340922176838\n",
      "0.1505342572927475\n",
      "0.10477942228317261\n",
      "0.018818670883774757\n",
      "0.13690772652626038\n",
      "0.1154763326048851\n",
      "0.01854989491403103\n",
      "0.13217724859714508\n",
      "0.09565355628728867\n",
      "0.018279731273651123\n",
      "0.17850235104560852\n",
      "0.09876954555511475\n",
      "0.018495388329029083\n",
      "0.1680506318807602\n",
      "0.11179536581039429\n",
      "0.01813049055635929\n",
      "0.17032195627689362\n",
      "0.10882166028022766\n",
      "0.018050985410809517\n",
      "0.19236312806606293\n",
      "0.10583420842885971\n",
      "0.018149858340620995\n",
      "0.14067256450653076\n",
      "0.09949318319559097\n",
      "0.01843562349677086\n",
      "0.15325118601322174\n",
      "0.11231175065040588\n",
      "0.01843392848968506\n",
      "0.13836130499839783\n",
      "0.10942541062831879\n",
      "0.01735948584973812\n",
      "0.12703058123588562\n",
      "0.12034795433282852\n",
      "0.017602017149329185\n",
      "0.13674506545066833\n",
      "0.11071639508008957\n",
      "0.017911532893776894\n",
      "0.14327670633792877\n",
      "0.10426461696624756\n",
      "0.018218839541077614\n",
      "0.19688040018081665\n",
      "0.11105542629957199\n",
      "0.018679499626159668\n",
      "0.138392835855484\n",
      "0.10839036852121353\n",
      "0.018067948520183563\n"
     ]
    }
   ],
   "source": [
    "# Training\n",
    "for epoch in range(num_epochs):\n",
    "    for i, (value,labels) in enumerate(train_dat1):\n",
    "        value = value.reshape(-1,sequence_length-4,input_size).to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        # forward pass\n",
    "        outputs = lstm_o(value)\n",
    "        loss = criterion(outputs.squeeze(),labels.squeeze())\n",
    "\n",
    "        # optimization step\n",
    "        op_o.zero_grad()\n",
    "        loss.backward()\n",
    "        op_o.step()\n",
    "\n",
    "        if i % 500 == 0:\n",
    "            print(loss.item())\n",
    "    \n",
    "    for i, (value,labels) in enumerate(train_dat2):\n",
    "        value = value.reshape(-1,sequence_length-4,input_size).to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        # forward pass\n",
    "        outputs = lstm_o(value)\n",
    "        loss = criterion(outputs.squeeze(),labels.squeeze())\n",
    "\n",
    "        # optimization step\n",
    "        op_o.zero_grad()\n",
    "        loss.backward()\n",
    "        op_o.step()\n",
    "\n",
    "        if i % 500 == 0:\n",
    "            print(loss.item())\n",
    "    \n",
    "    for i, (value,labels) in enumerate(train_dat3):\n",
    "        value = value.reshape(-1,sequence_length-4,input_size).to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        # forward pass\n",
    "        outputs = lstm_ma(value)\n",
    "        loss = criterion(outputs.squeeze(),labels.squeeze())\n",
    "\n",
    "        # optimization step\n",
    "        op_o.zero_grad()\n",
    "        loss.backward()\n",
    "        op_o.step()\n",
    "\n",
    "        if i % 500 == 0:\n",
    "            print(loss.item())\n",
    "    \n",
    "    scheduler_o.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0968)\n",
      "0.21617527019820715\n",
      "0.8615908622741699\n",
      "0.12745513767004013\n",
      "0.5605263157894737\n"
     ]
    }
   ],
   "source": [
    "# Evaluation\n",
    "lstm_ma.eval()\n",
    "mse = 0\n",
    "i = 0\n",
    "re = np.array([])\n",
    "with torch.no_grad():\n",
    "    for values, labels in test_dat:\n",
    "        values = values.reshape(-1,sequence_length-4,input_size).to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        outputs = lstm_ma(values)\n",
    "        mse += torch.sum((outputs-labels)**2)\n",
    "        i += len(labels.flatten())\n",
    "        re_tmp = np.array(np.abs(labels.flatten()-outputs.flatten()))\n",
    "        re = np.concatenate((re,re_tmp),axis=0)\n",
    "print(mse/i)\n",
    "mean_rerror = np.mean(re)\n",
    "max_rerror = np.max(re)\n",
    "median_rerror = np.median(re)\n",
    "print(mean_rerror)\n",
    "print(max_rerror)\n",
    "print(median_rerror)\n",
    "idx = re <= 0.15\n",
    "idx = idx + 0\n",
    "print(sum(idx)/len(idx))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "xgb 1.5.0\n"
     ]
    }
   ],
   "source": [
    "import xgboost as xgb\n",
    "print(\"xgb\",xgb.__version__)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "ad2bdc8ecc057115af97d19610ffacc2b4e99fae6737bb82f5d7fb13d2f2c186"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
