{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "#-*- coding:utf-8 -*-\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "import torchvision.transforms as transform\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch.utils.data as data\n",
    "\n",
    "train = pd.read_csv(\"data.csv\",parse_dates=[\"Date\"])\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyper-Parameters\n",
    "sequence_length = 20\n",
    "input_size = 2\n",
    "hidden_size = 128\n",
    "num_layers = 2\n",
    "output_size = 1\n",
    "batch_size = 100\n",
    "num_epochs = 200\n",
    "learning_rate = 5e-5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Build RNN(LSTM)\n",
    "class RNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_layers, output_size):\n",
    "        super(RNN, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        self.lstm = nn.LSTM(input_size, hidden_size, num_layers, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_size,output_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # set initial hidden and cell states\n",
    "        h0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(device) \n",
    "        c0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(device)\n",
    "        \n",
    "        # Forward propagate LSTM\n",
    "        out, _ = self.lstm(x, (h0, c0))  # out: tensor of shape (batch_size, seq_length, hidden_size)\n",
    "\n",
    "        # Decode the hidden state of the last time step\n",
    "        out = self.fc(out[:, -1, :])\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "input1 = np.array(train[\"GridPower_ma\"][19:])\n",
    "input2 = np.array(train[\"WindSpd_ma\"][19:])\n",
    "input = np.vstack((input1,input2)).T\n",
    "input = torch.tensor(input)\n",
    "gridpower = np.array(train[\"GridPower_ma\"][19:])\n",
    "gridpower = torch.tensor(gridpower)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "class mydata(data.Dataset):\n",
    "    def __init__(self, input_dat, y):\n",
    "        self.input_dat = input_dat\n",
    "        self.y = y\n",
    "        self.idx = list()\n",
    "        for item in input_dat:\n",
    "            self.idx.append(item)\n",
    "        pass\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        value = self.idx[index]\n",
    "        label = self.y[index]\n",
    "        return value,label\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Loader\n",
    "train_data = mydata(input,gridpower)\n",
    "train_dat = data.DataLoader(dataset=train_data, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = RNN(input_size, hidden_size, num_layers, output_size).to(device)\n",
    "\n",
    "\n",
    "# Loss and optimizer\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "for epoch in range(num_epochs):\n",
    "    # forward pass\n",
    "    outputs = model(input)\n",
    "    loss = criterion(outputs,gridpower)\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    print(loss.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "129.34706115722656\n",
      "118.79779052734375\n",
      "101.02709197998047\n",
      "118.80011749267578\n",
      "152.89306640625\n",
      "98.8016586303711\n",
      "143.74554443359375\n",
      "98.1234359741211\n",
      "116.13731384277344\n",
      "90.4646224975586\n",
      "119.52916717529297\n",
      "99.6573257446289\n",
      "98.36796569824219\n",
      "96.89983367919922\n",
      "78.20830535888672\n",
      "95.28868103027344\n",
      "73.05232238769531\n",
      "63.27443313598633\n",
      "81.84185791015625\n",
      "43.455997467041016\n",
      "43.26817321777344\n",
      "52.42966842651367\n",
      "46.25678634643555\n",
      "32.62325668334961\n",
      "45.36058044433594\n",
      "55.456390380859375\n",
      "54.60381317138672\n",
      "53.67306137084961\n",
      "59.88694763183594\n",
      "46.65523910522461\n",
      "41.61966323852539\n",
      "35.85218811035156\n",
      "33.14362335205078\n",
      "38.68270492553711\n",
      "33.48432540893555\n",
      "40.159454345703125\n",
      "40.37846755981445\n",
      "32.26632308959961\n",
      "38.50882339477539\n",
      "24.46969985961914\n",
      "30.948535919189453\n",
      "20.255390167236328\n",
      "16.36689567565918\n",
      "25.948305130004883\n",
      "24.584245681762695\n",
      "27.130399703979492\n",
      "24.562837600708008\n",
      "22.951000213623047\n",
      "27.587879180908203\n",
      "28.739683151245117\n",
      "18.506635665893555\n",
      "22.646390914916992\n",
      "23.825708389282227\n",
      "16.514677047729492\n",
      "36.61735153198242\n",
      "33.454132080078125\n",
      "19.430805206298828\n",
      "22.69356918334961\n",
      "9.149090766906738\n",
      "27.026758193969727\n",
      "23.504545211791992\n",
      "12.915360450744629\n",
      "21.519636154174805\n",
      "13.58178424835205\n",
      "24.74172592163086\n",
      "19.646446228027344\n",
      "23.385316848754883\n",
      "16.258468627929688\n",
      "18.40167999267578\n",
      "15.585773468017578\n",
      "21.447267532348633\n",
      "11.211930274963379\n",
      "17.074909210205078\n",
      "13.758444786071777\n",
      "19.322032928466797\n",
      "18.69780731201172\n",
      "17.633913040161133\n",
      "13.84478759765625\n",
      "13.251700401306152\n",
      "8.03092098236084\n",
      "16.98668670654297\n",
      "9.310076713562012\n",
      "15.677569389343262\n",
      "18.273700714111328\n",
      "11.357213973999023\n",
      "10.877859115600586\n",
      "16.129627227783203\n",
      "11.412078857421875\n",
      "16.283058166503906\n",
      "15.794572830200195\n",
      "11.963371276855469\n",
      "9.4616117477417\n",
      "11.1694974899292\n",
      "9.361372947692871\n",
      "6.6069207191467285\n",
      "8.32623291015625\n",
      "3.8632471561431885\n",
      "14.41101360321045\n",
      "7.7183380126953125\n",
      "9.718575477600098\n",
      "11.295912742614746\n",
      "11.380105018615723\n",
      "8.99311637878418\n",
      "7.729658603668213\n",
      "12.89908218383789\n",
      "6.306146144866943\n",
      "5.952411651611328\n",
      "8.218900680541992\n",
      "7.523317813873291\n",
      "10.467040061950684\n",
      "5.584468841552734\n",
      "6.226348400115967\n",
      "3.9560365676879883\n",
      "6.907490253448486\n",
      "9.058418273925781\n",
      "10.113685607910156\n",
      "9.336394309997559\n",
      "9.976511001586914\n",
      "7.61467170715332\n",
      "5.189658164978027\n",
      "5.5416951179504395\n",
      "7.9757184982299805\n",
      "4.9302496910095215\n",
      "7.392276763916016\n",
      "6.365350723266602\n",
      "3.3438189029693604\n",
      "8.09054946899414\n",
      "5.102940559387207\n",
      "4.748517990112305\n",
      "8.059615135192871\n",
      "6.703946590423584\n",
      "7.0719428062438965\n",
      "4.047222137451172\n",
      "4.712099552154541\n",
      "4.009789943695068\n",
      "8.36872673034668\n",
      "4.363681793212891\n",
      "3.7191383838653564\n",
      "5.208381175994873\n",
      "6.501499176025391\n",
      "2.6738555431365967\n",
      "5.005517482757568\n",
      "6.488577842712402\n",
      "4.234060764312744\n",
      "4.402887344360352\n",
      "3.971609592437744\n",
      "5.946807384490967\n",
      "2.992136240005493\n",
      "1.0962387323379517\n",
      "4.787176132202148\n",
      "5.397177219390869\n",
      "4.377317428588867\n",
      "4.1743011474609375\n",
      "5.706056118011475\n",
      "3.3980867862701416\n",
      "4.17758846282959\n",
      "1.0058363676071167\n",
      "3.5229332447052\n",
      "1.6694996356964111\n",
      "3.2209560871124268\n",
      "0.6939029693603516\n",
      "4.789000988006592\n",
      "3.4202065467834473\n",
      "2.5151424407958984\n",
      "3.627913236618042\n",
      "2.166083574295044\n",
      "3.3034350872039795\n",
      "1.4859176874160767\n",
      "2.610356330871582\n",
      "2.9146721363067627\n",
      "2.189845085144043\n",
      "1.9229429960250854\n",
      "1.9062272310256958\n",
      "1.574442744255066\n",
      "3.2239675521850586\n",
      "3.355078935623169\n",
      "1.7631704807281494\n",
      "0.7881229519844055\n",
      "1.8207744359970093\n",
      "3.786318302154541\n",
      "0.7206109762191772\n",
      "1.5466502904891968\n",
      "3.486077070236206\n",
      "2.229724645614624\n",
      "2.5650343894958496\n",
      "2.474369525909424\n",
      "1.2680407762527466\n",
      "2.7648873329162598\n",
      "0.6702018976211548\n",
      "1.9653056859970093\n",
      "0.803600549697876\n",
      "2.709383487701416\n",
      "1.041037917137146\n",
      "2.389324426651001\n",
      "1.5206211805343628\n",
      "0.7554166913032532\n",
      "1.7165234088897705\n",
      "0.5883708000183105\n",
      "0.46555840969085693\n",
      "1.9744768142700195\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "for epoch in range(num_epochs):\n",
    "    for i, (value,labels) in enumerate(train_dat):\n",
    "        value = value.reshape(-1,sequence_length,input_size).to(device)\n",
    "        value = value.to(torch.float32)\n",
    "        labels = labels.to(device)\n",
    "        labels = labels.to(torch.float32)\n",
    "\n",
    "        # forward pass\n",
    "        outputs = model(value)\n",
    "        loss = criterion(outputs.squeeze(),labels)\n",
    "\n",
    "        # optimization step\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if i % 100 == 0:\n",
    "            print(loss.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0])\n",
      "tensor([ 0.3201,  0.8337,  3.4599, 10.3992,  0.6335,  0.2896,  7.5089,  4.4695,\n",
      "         8.4194, 18.7016, 17.2056,  0.8775,  1.9219,  0.7886,  1.0361,  1.8945,\n",
      "         3.1402, 11.2544, 10.5998, 23.9145,  5.6102, 15.1279, 19.9027,  2.8245,\n",
      "         6.7379, 21.0713, 20.6244, 15.2556, 10.2007,  1.3615, 17.1013,  1.1815,\n",
      "         0.3201, 13.9788,  1.3490,  1.5591,  0.3201,  3.7489,  1.8452,  2.2540,\n",
      "        27.1625,  0.5988,  4.1117,  2.8245, 14.0348,  3.2650,  2.8245,  3.1066,\n",
      "         0.6766, 26.9691, 15.5057,  2.1659,  1.9589,  0.3201,  3.2065,  1.0902,\n",
      "         1.7929,  1.6506,  1.9237, 23.1998, 18.2980, 17.6155,  5.4831,  3.1020,\n",
      "         3.6879, 11.8116, 10.0081,  0.9648,  6.1145, 11.4874,  2.8912, 22.4463,\n",
      "         8.4103,  1.1183,  2.3281, 19.0115, 10.7622,  0.3201,  5.2161, 10.7164,\n",
      "        19.4116,  0.2392, 27.8417, 18.3774,  4.7404, 10.5605,  2.8245, 12.5458,\n",
      "         0.3503, 29.4205,  3.5862,  2.9583,  4.2322,  4.4790, 17.4529,  2.8245,\n",
      "         9.1953,  1.8202,  3.4910, 19.2537])\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "sum() received an invalid combination of arguments - got (axis=NoneType, out=NoneType, ), but expected one of:\n * (*, torch.dtype dtype)\n      didn't match because some of the keywords were incorrect: axis, out\n * (tuple of ints dim, bool keepdim, *, torch.dtype dtype)\n * (tuple of names dim, bool keepdim, *, torch.dtype dtype)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32me:\\Programmes\\Python\\BDAI\\Project\\project.ipynb Cell 10\u001b[0m in \u001b[0;36m<cell line: 4>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/e%3A/Programmes/Python/BDAI/Project/project.ipynb#X12sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m         \u001b[39mprint\u001b[39m(predicted)\n\u001b[0;32m     <a href='vscode-notebook-cell:/e%3A/Programmes/Python/BDAI/Project/project.ipynb#X12sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m         \u001b[39mprint\u001b[39m(labels)\n\u001b[1;32m---> <a href='vscode-notebook-cell:/e%3A/Programmes/Python/BDAI/Project/project.ipynb#X12sZmlsZQ%3D%3D?line=14'>15</a>\u001b[0m         mse \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m np\u001b[39m.\u001b[39;49msum((predicted\u001b[39m-\u001b[39;49mlabels)\u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49m\u001b[39m2\u001b[39;49m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/e%3A/Programmes/Python/BDAI/Project/project.ipynb#X12sZmlsZQ%3D%3D?line=16'>17</a>\u001b[0m \u001b[39mprint\u001b[39m(mse)\n",
      "File \u001b[1;32m<__array_function__ internals>:180\u001b[0m, in \u001b[0;36msum\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "File \u001b[1;32mc:\\ProgramData\\Anaconda3\\lib\\site-packages\\numpy\\core\\fromnumeric.py:2298\u001b[0m, in \u001b[0;36msum\u001b[1;34m(a, axis, dtype, out, keepdims, initial, where)\u001b[0m\n\u001b[0;32m   2295\u001b[0m         \u001b[39mreturn\u001b[39;00m out\n\u001b[0;32m   2296\u001b[0m     \u001b[39mreturn\u001b[39;00m res\n\u001b[1;32m-> 2298\u001b[0m \u001b[39mreturn\u001b[39;00m _wrapreduction(a, np\u001b[39m.\u001b[39;49madd, \u001b[39m'\u001b[39;49m\u001b[39msum\u001b[39;49m\u001b[39m'\u001b[39;49m, axis, dtype, out, keepdims\u001b[39m=\u001b[39;49mkeepdims,\n\u001b[0;32m   2299\u001b[0m                       initial\u001b[39m=\u001b[39;49minitial, where\u001b[39m=\u001b[39;49mwhere)\n",
      "File \u001b[1;32mc:\\ProgramData\\Anaconda3\\lib\\site-packages\\numpy\\core\\fromnumeric.py:84\u001b[0m, in \u001b[0;36m_wrapreduction\u001b[1;34m(obj, ufunc, method, axis, dtype, out, **kwargs)\u001b[0m\n\u001b[0;32m     82\u001b[0m             \u001b[39mreturn\u001b[39;00m reduction(axis\u001b[39m=\u001b[39maxis, dtype\u001b[39m=\u001b[39mdtype, out\u001b[39m=\u001b[39mout, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mpasskwargs)\n\u001b[0;32m     83\u001b[0m         \u001b[39melse\u001b[39;00m:\n\u001b[1;32m---> 84\u001b[0m             \u001b[39mreturn\u001b[39;00m reduction(axis\u001b[39m=\u001b[39;49maxis, out\u001b[39m=\u001b[39;49mout, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mpasskwargs)\n\u001b[0;32m     86\u001b[0m \u001b[39mreturn\u001b[39;00m ufunc\u001b[39m.\u001b[39mreduce(obj, axis, dtype, out, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mpasskwargs)\n",
      "\u001b[1;31mTypeError\u001b[0m: sum() received an invalid combination of arguments - got (axis=NoneType, out=NoneType, ), but expected one of:\n * (*, torch.dtype dtype)\n      didn't match because some of the keywords were incorrect: axis, out\n * (tuple of ints dim, bool keepdim, *, torch.dtype dtype)\n * (tuple of names dim, bool keepdim, *, torch.dtype dtype)\n"
     ]
    }
   ],
   "source": [
    "# See Output\n",
    "model.eval()\n",
    "mse = 0\n",
    "with torch.no_grad():\n",
    "    for values,labels in train_dat:\n",
    "        values = values.reshape(-1,sequence_length,input_size).to(device)\n",
    "        values = values.to(torch.float32)\n",
    "        labels = labels.to(device)\n",
    "        labels = labels.to(torch.float32)\n",
    "\n",
    "        outputs = model(values)\n",
    "        _, predicted = torch.max(outputs.data,1)\n",
    "        print(predicted)\n",
    "        print(labels)\n",
    "        mse += np.sum((predicted-labels)**2)\n",
    "\n",
    "print(mse)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "ad2bdc8ecc057115af97d19610ffacc2b4e99fae6737bb82f5d7fb13d2f2c186"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
